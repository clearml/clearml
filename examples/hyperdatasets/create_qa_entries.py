"""
Create a HyperDataset populated with raw Q&A pairs.

The script demonstrates how to build Q&A entries, optionally enrich them with
vector embeddings generated by a small local model, and upload them to a
HyperDataset version.

Example usage:

    python examples/hyperdatasets/create_qa_entries.py \
        --project "HyperDatasets Examples" \
        --dataset-name "qa-demo" \
        --version-name "version" \
        --embed \
        --embedding-model sentence-transformers/all-MiniLM-L6-v2

To provide your own Q&A content, supply a JSON file containing a list of
objects with "question" and "answer" fields via --qa-json.
"""

import argparse
import html
import json
import re
import tempfile
import textwrap
import uuid
from pathlib import Path
from typing import Iterable, List, Optional, Tuple

# ClearML HyperDataset primitives (dataset, entries, and helpers)
from clearml.hyperdatasets import (
    HyperDataset,
    DataEntry,
    DataSubEntry,
)
from clearml import StorageManager
from clearml.backend_api.session.session import Session


# ClearML sub-entry representing a single text snippet within the Q&A pair
class QADataSubEntry(DataSubEntry):
    def __init__(self, name: str, text: str, role: str, preview_source: Optional[str] = None):
        super().__init__(
            name=name,
            source=f"text://{uuid.uuid4().hex}",  # or hash of text sha256(text)
            preview_source=preview_source,
            metadata={"text": text, "role": role},
        )


# ClearML data entry aggregating the question/answer into a single frame
class QADataEntry(DataEntry):
    def __init__(
        self,
        question: str,
        answer: str,
        *,
        reference: Optional[str] = None,
        tags: Optional[Iterable[str]] = None,
    ):
        metadata = {
            "question": question,
            "answer": answer,
        }
        if reference:
            metadata["reference"] = reference
        if tags:
            metadata["tags"] = list(tags)
        super().__init__(metadata=metadata)

    @property
    def question(self) -> str:
        return self._metadata.get("question", "")

    @property
    def answer(self) -> str:
        return self._metadata.get("answer", "")


def parse_args() -> argparse.Namespace:
    description = textwrap.dedent(__doc__ or "").strip()
    parser = argparse.ArgumentParser(
        description=description or None,
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("--project", default="HyperDatasets Examples", help="ClearML project name")
    parser.add_argument("--dataset-name", required=True, help="HyperDataset collection name")
    parser.add_argument("--version-name", required=True, help="HyperDataset version name")
    parser.add_argument("--description", default="Q&A demo HyperDataset", help="Version description")
    parser.add_argument(
        "--qa-json",
        type=Path,
        help="Path to a JSON file containing a list of {question, answer, reference?, tags?}",
    )
    parser.add_argument("--embed", action="store_true", help="Generate vector embeddings for each Q&A pair")
    parser.add_argument(
        "--embedding-model",
        default="sentence-transformers/all-MiniLM-L6-v2",
        help="SentenceTransformer model name or local path used when --embed is set",
    )
    parser.add_argument(
        "--embedding-device",
        default=None,
        help="Optional device string passed to SentenceTransformer (e.g. 'cpu', 'cuda')",
    )
    parser.add_argument(
        "--vector-field",
        help="Metadata field used to store the embedding vector",
    )
    parser.add_argument(
        "--normalize",
        action="store_true",
        help="L2-normalize the generated embeddings before storing them",
    )
    return parser.parse_args()


def load_qa_pairs(qa_json: Optional[Path]) -> List[dict]:
    if qa_json:
        with qa_json.open("r", encoding="utf-8") as fp:
            data = json.load(fp)
        if not isinstance(data, list):
            raise ValueError("QA JSON must contain a list of objects")
        return data

    # Default in-script examples.
    return [
        {
            "question": "What is ClearML HyperDataset?",
            "answer": "A ClearML data structure that lets you manage structured data entries with optional assets.",
            "reference": "https://clear.ml/docs/latest/docs/hyperdatasets",
            "tags": ["docs", "product"],
        },
        {
            "question": "How can I add items into a HyperDataset?",
            "answer": "Create DataEntry instances, attach sub-entries when needed, and call add_data_entries().",
            "tags": ["usage"],
        },
        {
            "question": "Why store embeddings on a HyperDataset?",
            "answer": "Embeddings enable semantic search and similarity queries directly on dataset entries.",
            "tags": ["search"],
        },
    ]


def maybe_encode_embeddings(
    qa_pairs: List[dict],
    *,
    model_name: str,
    device: Optional[str],
    normalize: bool,
) -> Optional[List[List[float]]]:
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError as exc:
        raise RuntimeError("sentence-transformers is required for --embed") from exc

    model = SentenceTransformer(model_name, device=device)
    sentences = [
        f"question: {item.get('question', '')}\nanswer: {item.get('answer', '')}"
        for item in qa_pairs
    ]
    embeddings = model.encode(sentences, normalize_embeddings=normalize)
    return [list(map(float, emb)) for emb in embeddings]


def build_entries(
    qa_pairs: List[dict],
    embeddings: Optional[List[List[float]]],
    vector_field: Optional[str],
    preview_sources: Optional[List[Optional[str]]] = None,
) -> Tuple[List[QADataEntry], Optional[int]]:
    entries: List[QADataEntry] = []
    vector_dims: Optional[int] = None
    for idx, item in enumerate(qa_pairs):
        question = item.get("question", "")
        answer = item.get("answer", "")
        if not question or not answer:
            raise ValueError(f"Q&A item at index {idx} must include both 'question' and 'answer'")

        preview_uri = None
        if preview_sources and idx < len(preview_sources):
            preview_uri = preview_sources[idx]

        entry = QADataEntry(
            question=question,
            answer=answer,
            reference=item.get("reference"),
            tags=item.get("tags"),
        )
        entry.add_sub_entries(
            [
                QADataSubEntry(name="question", text=question, role="question", preview_source=preview_uri),
                QADataSubEntry(name="answer", text=answer, role="answer", preview_source=preview_uri),
            ]
        )

        if embeddings:
            if not vector_field:
                raise ValueError("vector_field must be provided when embeddings are supplied")
            vector = embeddings[idx]
            entry.set_vector(vector, metadata_field=vector_field)
            if vector_dims is None:
                vector_dims = len(vector)
            elif vector_dims != len(vector):
                raise ValueError("All embedding vectors must share the same dimensionality")

        entries.append(entry)
    return entries, vector_dims


def _resolve_vector_dims(embeddings: Optional[List[List[float]]]) -> Optional[int]:
    if not embeddings:
        return None
    if not embeddings[0]:
        raise ValueError("Embedding vectors must not be empty")
    dims = len(embeddings[0])
    for idx, vector in enumerate(embeddings[1:], start=1):
        if len(vector) != dims:
            raise ValueError(
                f"Embedding at index {idx} has dimensionality {len(vector)}; expected {dims}"
            )
    return dims


def _build_preview_base_url(app_host: str, version_id: Optional[str]) -> Optional[str]:
    host = (app_host or "").rstrip("/")
    if not host or not version_id:
        return None
    return f"{host}/files/datasets/{version_id}/clearml-docs/docs/webapp"


def _preview_file_name(question: str, index: int) -> str:
    slug = re.sub(r"[^a-z0-9]+", "-", (question or "").lower()).strip("-")
    if slug:
        slug = slug[:60].strip("-")
    if not slug:
        slug = f"qa-entry-{index:04d}"
    return f"{slug}-{uuid.uuid4().hex[:8]}"


def _render_preview_html(question: str, answer: str) -> str:
    escaped_question = html.escape(question)
    escaped_answer = html.escape(answer).replace("\n", "<br />\n")
    return f"""<!DOCTYPE html>
<html lang=\"en\">
<head>
  <meta charset=\"utf-8\" />
  <title>{escaped_question}</title>
  <style>body{{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif;margin:1.5rem;line-height:1.5;}} .question{{font-size:1.1rem;font-weight:600;}} .answer{{margin-top:1rem;}}</style>
</head>
<body>
  <div class=\"question\">{escaped_question}</div>
  <div class=\"answer\">{escaped_answer}</div>
</body>
</html>
"""


def upload_entry_previews(
    qa_pairs: List[dict],
    preview_base_url: Optional[str],
) -> Optional[List[str]]:
    if not preview_base_url:
        return None

    preview_urls: List[str] = []
    with tempfile.TemporaryDirectory() as preview_dir:
        preview_dir_path = Path(preview_dir)
        for idx, item in enumerate(qa_pairs):
            question = item.get("question", "") or ""
            answer = item.get("answer", "") or ""
            preview_name = _preview_file_name(question, idx)
            local_path = preview_dir_path / f"{preview_name}.html"
            local_path.write_text(_render_preview_html(question, answer), encoding="utf-8")
            remote_url = StorageManager.upload_file(
                local_file=local_path.as_posix(),
                remote_url=f"{preview_base_url}/{preview_name}.html",
            )
            preview_urls.append(remote_url)
    return preview_urls


def main():
    args = parse_args()

    qa_pairs = load_qa_pairs(args.qa_json)

    embeddings = None
    if args.embed:
        embeddings = maybe_encode_embeddings(
            qa_pairs,
            model_name=args.embedding_model,
            device=args.embedding_device,
            normalize=args.normalize,
        )

    vector_field = args.vector_field
    if embeddings and not vector_field:
        raise ValueError("--vector-field must be provided when --embed is used")

    vector_dims = _resolve_vector_dims(embeddings)

    field_mappings = None
    if vector_dims:
        field_path = vector_field if vector_field.startswith("meta.") else f"meta.{vector_field}"
        # ClearML field mapping informs the server about the dense vector metadata schema
        field_mappings = {
            field_path: {
                "type": "dense_vector",
                "element_type": "float",
                "dims": vector_dims,
            }
        }

    # ClearML HyperDataset version handle (creates if missing)
    dataset = HyperDataset(
        project_name=args.project,
        dataset_name=args.dataset_name,
        version_name=args.version_name,
        description=args.description,
        field_mappings=field_mappings,
    )

    app_host = Session.get_files_server_host()
    preview_base_url = _build_preview_base_url(app_host, dataset.version_id)
    preview_sources = upload_entry_previews(qa_pairs, preview_base_url)

    entries, _ = build_entries(qa_pairs, embeddings, vector_field, preview_sources=preview_sources)

    # Upload entries so ClearML handles storage and indexing
    errors = dataset.add_data_entries(entries, upload_local_files_destination=None, force_upload=True)
    if errors.get("register"):
        raise RuntimeError(f"Failed registering entries: {errors['register']}")

    print(
        "Created HyperDataset version: project={project} dataset={dataset} version={version}".format(
            project=dataset.project_id,
            dataset=dataset.dataset_id,
            version=dataset.version_id,
        )
    )


if __name__ == "__main__":
    main()
